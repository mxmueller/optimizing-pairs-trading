{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kneed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import coint\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Basic configuration\n",
    "DATE_CONFIG = {\n",
    "    'TRAIN_START': pd.Timestamp('2021-02-02'),\n",
    "    'TRAIN_END': pd.Timestamp('2024-01-01'),\n",
    "    'TEST_END': pd.Timestamp('2025-01-01'),\n",
    "    'TRADING_DAYS_PER_YEAR': 252  \n",
    "}\n",
    "\n",
    "def get_training_period():\n",
    "    return {\n",
    "        'start': DATE_CONFIG['TRAIN_START'],\n",
    "        'end': DATE_CONFIG['TRAIN_END']\n",
    "    }\n",
    "\n",
    "def get_test_period():\n",
    "    return {\n",
    "        'start': DATE_CONFIG['TRAIN_END'],\n",
    "        'end': DATE_CONFIG['TEST_END']\n",
    "    }\n",
    "\n",
    "def get_training_days():\n",
    "    years = (DATE_CONFIG['TRAIN_END'] - DATE_CONFIG['TRAIN_START']).days / 365\n",
    "    return int(years * DATE_CONFIG['TRADING_DAYS_PER_YEAR'])\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('classic')\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path):\n",
    "\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    mask = (df['date'] >= DATE_CONFIG['TRAIN_START']) & \\\n",
    "           (df['date'] <= DATE_CONFIG['TEST_END'])\n",
    "    df = df[mask]\n",
    "    \n",
    "    price_matrix = df.pivot(index='date', columns='symbol', values='close')\n",
    "    \n",
    "    symbols = price_matrix.columns.tolist()\n",
    "    \n",
    "    print(f\"Loaded data from {DATE_CONFIG['TRAIN_START']} to {DATE_CONFIG['TEST_END']}\")\n",
    "    print(f\"Total symbols: {len(symbols)}\")\n",
    "    print(f\"Total trading days: {len(price_matrix)}\")\n",
    "    \n",
    "    return price_matrix, symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loade Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_matrix, symbols = load_and_prepare_data('./nasdaq_daily.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$ \\text{Rendite} = \\frac{1}{T} \\sum_{t=1}^{T} \\frac{P_t - P_{t-1}}{P_{t-1}} \\times \\text{Trading days per year} $$\n",
    "\n",
    "\n",
    "$$ \\text{VolatilitÃ¤t} = \\sqrt{\\frac{1}{T-1} \\sum_{t=1}^{T} \\left( \\frac{P_t - P_{t-1}}{P_{t-1}} - \\mu \\right)^2} \\times \\sqrt{\\text{Trading days per year}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(price_matrix):\n",
    "    returns = price_matrix.pct_change().mean() * DATE_CONFIG['TRADING_DAYS_PER_YEAR']\n",
    "    metrics = pd.DataFrame(returns, columns=['returns'])\n",
    "    metrics['volatility'] = price_matrix.pct_change().std() * np.sqrt(DATE_CONFIG['TRADING_DAYS_PER_YEAR'])\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = calculate_metrics(price_matrix)\n",
    "print(\"Erste 5 Zeilen der Metriken:\")\n",
    "print(metrics.head())\n",
    "print(\"\\nBeschreibung der Metriken:\")\n",
    "print(metrics.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scale Transform\n",
    "The StandardScaler transforms our features (returns and volatility) to have zero mean and unit variance, which eliminates the scale difference between our variables and prevents higher magnitude features from dominating. This standardization is crucial for many machine learning algorithms as it ensures that all features contribute equally to the model and helps prevent numerical instabilities during the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_metrics(metrics):\n",
    "    scaler = StandardScaler()\n",
    "    scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(metrics),\n",
    "        columns=metrics.columns,\n",
    "        index=metrics.index\n",
    "    )\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scale_metrics(metrics)\n",
    "print(\"Erste 5 Zeilen der skalierten Daten:\")\n",
    "print(X.head())\n",
    "print(\"\\nBeschreibung der skalierten Daten:\")\n",
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affinity Propagation Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = AffinityPropagation()\n",
    "ap.fit(X)\n",
    "labels1 = ap.predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot(111)\n",
    "scatter = ax.scatter(X.iloc[:,0], X.iloc[:,1], c=labels1, cmap='rainbow')\n",
    "ax.set_title('Affinity Propagation Clustering Results')\n",
    "ax.set_xlabel('Mean Return')\n",
    "ax.set_ylabel('Volatility')\n",
    "plt.colorbar(scatter)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "#Extract the cluster centers and labels\n",
    "cci = ap.cluster_centers_indices_\n",
    "labels2 = ap.labels_\n",
    "\n",
    "#Print their number\n",
    "clusters = len(cci)\n",
    "print('The number of clusters is:',clusters)\n",
    "\n",
    "#Plot the results\n",
    "X_ap = np.asarray(X)\n",
    "plt.close('all')\n",
    "plt.figure(1)\n",
    "plt.clf\n",
    "fig=plt.figure(figsize=(15,10))\n",
    "colors = cycle('cmykrgbcmykrgbcmykrgbcmykrgb')\n",
    "for k, col in zip(range(clusters),colors):\n",
    "    cluster_members = labels2 == k\n",
    "    cluster_center = X_ap[cci[k]]\n",
    "    plt.plot(X_ap[cluster_members, 0], X_ap[cluster_members, 1], col + '.')\n",
    "    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col, markeredgecolor='k', markersize=12)\n",
    "    for x in X_ap[cluster_members]:\n",
    "        plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\n",
    "\n",
    "plt.title('Affinity Propagation Clustering Results with Connections')\n",
    "plt.xlabel('Mean Return')\n",
    "plt.ylabel('Volatility')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_series_ap = pd.Series(index=X.index, data=ap.labels_.flatten())\n",
    "\n",
    "cluster_size_limit = 1000\n",
    "counts = clustered_series_ap.value_counts()\n",
    "ticker_count = counts[(counts>1) & (counts<=cluster_size_limit)]\n",
    "print(\"Number of clusters:\", len(ticker_count))\n",
    "print(\"Number of Pairs:\", (ticker_count*(ticker_count-1)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cointegrated_pairs(price_matrix, pvalue_threshold=0.05):\n",
    "    n = price_matrix.shape[1]\n",
    "    score_matrix = np.zeros((n, n))\n",
    "    pvalue_matrix = np.ones((n, n))\n",
    "    symbols = price_matrix.columns\n",
    "    pairs = []\n",
    "    results = []\n",
    "    \n",
    "    total_pairs = sum(range(n))\n",
    "    with tqdm(total=total_pairs, desc=\"Analyzing pairs\") as pbar:\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                S1 = price_matrix[symbols[i]]\n",
    "                S2 = price_matrix[symbols[j]]\n",
    "                \n",
    "                result = coint(S1, S2)\n",
    "                score = result[0]\n",
    "                pvalue = result[1]\n",
    "                \n",
    "                score_matrix[i, j] = score\n",
    "                pvalue_matrix[i, j] = pvalue\n",
    "                \n",
    "                results.append({\n",
    "                    'symbol1': symbols[i],\n",
    "                    'symbol2': symbols[j],\n",
    "                    'p_value': pvalue,\n",
    "                    'score': score\n",
    "                })\n",
    "                \n",
    "                if pvalue <= pvalue_threshold:\n",
    "                    pairs.append((symbols[i], symbols[j]))\n",
    "                    \n",
    "                pbar.update(1)\n",
    "    \n",
    "    return score_matrix, pvalue_matrix, pairs, results\n",
    "\n",
    "def analyze_pairs(price_matrix, pvalue_threshold=0.05):\n",
    "    score_matrix, pvalue_matrix, pairs, results = find_cointegrated_pairs(\n",
    "        price_matrix, \n",
    "        pvalue_threshold\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nAnalysis complete!\")\n",
    "    print(f\"Found {len(pairs)} cointegrated pairs\")\n",
    "    print(f\"Total pairs analyzed: {len(results)}\")\n",
    "    \n",
    "    summary_df = pd.DataFrame(results)\n",
    "    summary_df['is_cointegrated'] = summary_df['p_value'] <= pvalue_threshold\n",
    "    \n",
    "    return score_matrix, pvalue_matrix, pairs, summary_df\n",
    "\n",
    "def plot_cointegration_heatmap(pvalue_matrix, symbols, max_pvalue=0.98):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    mask = (pvalue_matrix >= max_pvalue)\n",
    "    \n",
    "    sns.heatmap(\n",
    "        pvalue_matrix, \n",
    "        xticklabels=symbols, \n",
    "        yticklabels=symbols, \n",
    "        cmap='RdYlGn_r',\n",
    "        mask=mask\n",
    "    )\n",
    "    \n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.title('Cointegration p-values heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs_with_clusters = []\n",
    "\n",
    "for cluster_id in np.unique(ap.labels_):\n",
    "    cluster_mask = ap.labels_ == cluster_id\n",
    "    cluster_symbols = X.index[cluster_mask]\n",
    "    \n",
    "    if len(cluster_symbols) > 1:\n",
    "        cluster_prices = price_matrix[cluster_symbols]\n",
    "        score_matrix, pvalue_matrix, pairs, _ = analyze_pairs(\n",
    "            cluster_prices,\n",
    "            pvalue_threshold=0.03\n",
    "        )\n",
    "        \n",
    "        if len(pairs) > 0:\n",
    "            for pair in pairs:\n",
    "                all_pairs_with_clusters.append({\n",
    "                    'pair': pair,\n",
    "                    'cluster': cluster_id\n",
    "                })\n",
    "            print(f\"\\nCluster {cluster_id} pairs:\")\n",
    "            for pair in pairs:\n",
    "                print(f\"{pair[0]} - {pair[1]}\")\n",
    "                \n",
    "            plot_cointegration_heatmap(pvalue_matrix, cluster_symbols)\n",
    "\n",
    "all_pairs = [item['pair'] for item in all_pairs_with_clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = np.unique(all_pairs)\n",
    "X_data = pd.DataFrame(index=X.index, data=X).T\n",
    "in_pairs_series = pd.Series(index=stocks, data=[ap.labels_[list(X.index).index(stock)] for stock in stocks])\n",
    "stocks = list(np.unique(all_pairs))\n",
    "X_pairs = X_data.T.loc[stocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_tsne = TSNE(learning_rate=30, perplexity=5, random_state=42, n_jobs=-1).fit_transform(X_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,12), facecolor='white')\n",
    "plt.clf()\n",
    "plt.gca().set_facecolor('#f8f9fa')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "for item in all_pairs_with_clusters:\n",
    "    pair = item['pair']\n",
    "    cluster = item['cluster']\n",
    "    loc1 = X_pairs.index.get_loc(pair[0])\n",
    "    loc2 = X_pairs.index.get_loc(pair[1])\n",
    "    x1, y1 = X_tsne[loc1, :]\n",
    "    x2, y2 = X_tsne[loc2, :]\n",
    "    plt.plot([x1, x2], [y1, y2], '-', alpha=0.4, linewidth=1.5, color='#4a90e2')\n",
    "\n",
    "scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], \n",
    "                     s=300,\n",
    "                     alpha=0.7,\n",
    "                     c=in_pairs_series.values,\n",
    "                     cmap='tab20',\n",
    "                     edgecolor='white',\n",
    "                     linewidth=2)\n",
    "\n",
    "for x, y, name in zip(X_tsne[:,0], X_tsne[:,1], X_pairs.index):\n",
    "    plt.annotate(name,\n",
    "                (x,y),\n",
    "                textcoords=\"offset points\",\n",
    "                xytext=(0,10),\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                fontsize=11,\n",
    "                fontweight='bold',\n",
    "                bbox=dict(facecolor='white', \n",
    "                         edgecolor='none',\n",
    "                         alpha=0.7,\n",
    "                         pad=1))\n",
    "\n",
    "plt.title('Stock Pairs Clustering Visualization (Same Cluster Only)', \n",
    "          fontsize=16, \n",
    "          pad=20,\n",
    "          fontweight='bold')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(series):\n",
    "    return (series - series.mean()) / np.std(series)\n",
    "\n",
    "def calculate_spread(data, symbol1, symbol2, start_date=None, end_date=None):\n",
    "    if start_date:\n",
    "        mask = (data.index >= start_date) & (data.index <= end_date)\n",
    "        data = data[mask]\n",
    "    \n",
    "    # Calculate ratio and z-score\n",
    "    ratios = data[symbol1] / data[symbol2]\n",
    "    zscore_ratios = zscore(ratios)\n",
    "    \n",
    "    return ratios, zscore_ratios\n",
    "\n",
    "def trade(S1_train, S2_train, S1_test, S2_test, symbol1, symbol2, window1=5, window2=60):\n",
    "    ratios_train = S1_train / S2_train\n",
    "    ma2_train = ratios_train.rolling(window=window2, center=False).mean()\n",
    "    std_train = ratios_train.rolling(window=window2, center=False).std()\n",
    "    \n",
    "    ratios_test = S1_test / S2_test\n",
    "    trades = []\n",
    "    trade_id = 0\n",
    "    position = 0\n",
    "    entry_prices = None\n",
    "    entry_date = None\n",
    "    \n",
    "    for i in range(len(ratios_test)):\n",
    "        current_ratio = ratios_test.iloc[i]\n",
    "        current_date = ratios_test.index[i]\n",
    "        \n",
    "        ma2_test = ratios_test.iloc[:i+1].rolling(window=window2, center=False).mean().iloc[-1]\n",
    "        std_test = ratios_test.iloc[:i+1].rolling(window=window2, center=False).std().iloc[-1]\n",
    "        zscore = (current_ratio - ma2_test) / std_test\n",
    "        \n",
    "        if position == 0:\n",
    "            if zscore > 1.0:\n",
    "                entry_date = current_date\n",
    "                entry_prices = {\n",
    "                    symbol1: {\"price\": S1_test.iloc[i], \"type\": \"short\"},\n",
    "                    symbol2: {\"price\": S2_test.iloc[i], \"type\": \"long\"}\n",
    "                }\n",
    "                position = -1\n",
    "                \n",
    "            elif zscore < -1.0:\n",
    "                entry_date = current_date\n",
    "                entry_prices = {\n",
    "                    symbol1: {\"price\": S1_test.iloc[i], \"type\": \"long\"},\n",
    "                    symbol2: {\"price\": S2_test.iloc[i], \"type\": \"short\"}\n",
    "                }\n",
    "                position = 1\n",
    "                \n",
    "        elif abs(zscore) < 0.5 and position != 0:\n",
    "            for symbol in [symbol1, symbol2]:\n",
    "                trades.append({\n",
    "                    'trade_id': trade_id,\n",
    "                    'symbol': symbol,\n",
    "                    'entry_date': entry_date,\n",
    "                    'entry_price': entry_prices[symbol][\"price\"],\n",
    "                    'exit_date': current_date,\n",
    "                    'exit_price': S1_test.iloc[i] if symbol == symbol1 else S2_test.iloc[i],\n",
    "                    'position_type': entry_prices[symbol][\"type\"],\n",
    "                    'paired_symbol': symbol2 if symbol == symbol1 else symbol1\n",
    "                })\n",
    "            position = 0\n",
    "            trade_id += 1\n",
    "            \n",
    "    return trades\n",
    "\n",
    "def backtest_pairs(price_matrix, pairs, train_end_date):\n",
    "    all_trades = []\n",
    "    \n",
    "    for symbol1, symbol2 in pairs:\n",
    "        training_mask = price_matrix.index < train_end_date\n",
    "        \n",
    "        S1_train = price_matrix[symbol1][training_mask]\n",
    "        S2_train = price_matrix[symbol2][training_mask]\n",
    "        S1_test = price_matrix[symbol1][~training_mask]\n",
    "        S2_test = price_matrix[symbol2][~training_mask]\n",
    "        \n",
    "        pair_trades = trade(S1_train, S2_train, S1_test, S2_test, symbol1, symbol2)\n",
    "        all_trades.extend(pair_trades)\n",
    "    \n",
    "    trades_df = pd.DataFrame(all_trades)\n",
    "    trades_df.to_parquet('./results/apcluster_zscore_results.parquet')\n",
    "    \n",
    "    return trades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades_df = backtest_pairs(price_matrix, all_pairs, DATE_CONFIG['TRAIN_END'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug ð ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gefundene Pairs:\n",
      "ADSK - TTWO\n",
      "ANSS - TTWO\n",
      "ANSS - WDAY\n",
      "TTWO - WDAY\n",
      "CDW - XEL\n",
      "CSX - CTSH\n",
      "CSX - ROP\n",
      "EA - EXC\n",
      "EA - HON\n",
      "EA - PEP\n",
      "EA - TXN\n",
      "EXC - HON\n",
      "KDP - MNST\n",
      "AVGO - AXON\n",
      "CDNS - ORLY\n",
      "ODFL - SNPS\n",
      "ADI - CCEP\n",
      "ADI - CTAS\n",
      "ADI - LIN\n",
      "ADI - MSFT\n",
      "ADI - VRSK\n",
      "FAST - MSFT\n",
      "MRVL - TTD\n",
      "\n",
      "Gesamtanzahl der Pairs: 23\n"
     ]
    }
   ],
   "source": [
    "print(\"Gefundene Pairs:\")\n",
    "for pair in all_pairs:\n",
    "    print(f\"{pair[0]} - {pair[1]}\")\n",
    "print(f\"\\nGesamtanzahl der Pairs: {len(all_pairs)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

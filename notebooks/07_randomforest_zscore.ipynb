{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.analysis.cointegration import find_cointegrated_pairs, analyze_pairs, plot_cointegration_heatmap\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import coint\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATE_CONFIG = {\n",
    "    'TRAIN_START': pd.Timestamp('2021-02-02'),\n",
    "    'TRAIN_END': pd.Timestamp('2024-01-01'),\n",
    "    'TEST_END': pd.Timestamp('2025-01-01'),\n",
    "    'TRADING_DAYS_PER_YEAR': 252  \n",
    "}\n",
    "\n",
    "def get_training_period():\n",
    "    return {\n",
    "        'start': DATE_CONFIG['TRAIN_START'],\n",
    "        'end': DATE_CONFIG['TRAIN_END']\n",
    "    }\n",
    "\n",
    "def get_test_period():\n",
    "    return {\n",
    "        'start': DATE_CONFIG['TRAIN_END'],\n",
    "        'end': DATE_CONFIG['TEST_END']\n",
    "    }\n",
    "\n",
    "def get_training_days():\n",
    "    years = (DATE_CONFIG['TRAIN_END'] - DATE_CONFIG['TRAIN_START']).days / 365\n",
    "    return int(years * DATE_CONFIG['TRADING_DAYS_PER_YEAR'])\n",
    "\n",
    "plt.style.use('classic')\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path):\n",
    "\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    mask = (df['date'] >= DATE_CONFIG['TRAIN_START']) & \\\n",
    "           (df['date'] <= DATE_CONFIG['TEST_END'])\n",
    "    df = df[mask]\n",
    "    \n",
    "    price_matrix = df.pivot(index='date', columns='symbol', values='close')\n",
    "    \n",
    "    symbols = price_matrix.columns.tolist()\n",
    "    \n",
    "    print(f\"Loaded data from {DATE_CONFIG['TRAIN_START']} to {DATE_CONFIG['TEST_END']}\")\n",
    "    print(f\"Total symbols: {len(symbols)}\")\n",
    "    print(f\"Total trading days: {len(price_matrix)}\")\n",
    "    \n",
    "    return price_matrix, symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs(cointegrated_pairs):\n",
    "    return cointegrated_pairs\n",
    "\n",
    "def calculate_returns_and_spreads(price_matrix, cointegrated_pairs):\n",
    "    returns = price_matrix.pct_change().dropna()\n",
    "    \n",
    "    pairs = generate_pairs(cointegrated_pairs)\n",
    "    \n",
    "    spreads = pd.DataFrame(index=returns.index)\n",
    "    for s1, s2 in pairs:\n",
    "        spreads[f'{s1}_{s2}_spread'] = returns[s1] - returns[s2]\n",
    "        \n",
    "    return returns, spreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ml_data(returns, spreads, train_period, test_period, lookback=3):\n",
    "    ml_datasets = {}\n",
    "    \n",
    "    for spread_col in spreads.columns:\n",
    "        sym1, sym2 = spread_col.replace('_spread', '').split('_')\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            f'{sym1}_return': returns[sym1],\n",
    "            f'{sym2}_return': returns[sym2]\n",
    "        })\n",
    "        \n",
    "        for t in range(1, lookback+1):\n",
    "            df[f'{sym1}_return_t-{t}'] = df[f'{sym1}_return'].shift(t)\n",
    "            df[f'{sym2}_return_t-{t}'] = df[f'{sym2}_return'].shift(t)\n",
    "        \n",
    "        spread_next_day = (df[f'{sym1}_return'] - df[f'{sym2}_return']).shift(-1)\n",
    "        df['target'] = np.where(spread_next_day > 0, 1, 0)\n",
    "        \n",
    "        feature_cols = [col for col in df.columns if 't-' in col]\n",
    "        features = df[feature_cols].copy()\n",
    "        \n",
    "        clean_idx = features.dropna().index\n",
    "        features = features.loc[clean_idx]\n",
    "        target = df.loc[clean_idx, 'target']\n",
    "    \n",
    "        \n",
    "        train_mask = (features.index >= train_period['start']) & (features.index < train_period['end'])\n",
    "        test_mask = (features.index >= test_period['start']) & (features.index < test_period['end'])\n",
    "        \n",
    "        ml_datasets[f'{sym1}_{sym2}'] = {\n",
    "            'X_train': features[train_mask],\n",
    "            'X_test': features[test_mask],\n",
    "            'y_train': target[train_mask],\n",
    "            'y_test': target[test_mask]\n",
    "        }\n",
    "        \n",
    "    return ml_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_models(ml_datasets, coint_results):\n",
    "   results = {}\n",
    "   \n",
    "   for pair, data in tqdm(ml_datasets.items(), desc=\"Training models\"):\n",
    "       sym1, sym2 = pair.split('_')\n",
    "       \n",
    "       p_value = coint_results[\n",
    "           ((coint_results['symbol1'] == sym1) & (coint_results['symbol2'] == sym2)) |\n",
    "           ((coint_results['symbol1'] == sym2) & (coint_results['symbol2'] == sym1))\n",
    "       ]['p_value'].iloc[0]\n",
    "       \n",
    "       rf = RandomForestClassifier(\n",
    "           n_estimators=100,\n",
    "           random_state=42\n",
    "       )\n",
    "       \n",
    "       rf.fit(data['X_train'], data['y_train'])\n",
    "       predictions = rf.predict(data['X_test'])\n",
    "       \n",
    "       f1 = f1_score(data['y_test'], predictions)\n",
    "       \n",
    "       weighted_score = 0.6 * f1 + 0.4 * (1 - p_value)\n",
    "       \n",
    "       results[pair] = {\n",
    "           'model': rf,\n",
    "           'accuracy': accuracy_score(data['y_test'], predictions),\n",
    "           'precision': precision_score(data['y_test'], predictions),\n",
    "           'recall': recall_score(data['y_test'], predictions),\n",
    "           'f1': f1,\n",
    "           'p_value': p_value,\n",
    "           'weighted_score': weighted_score\n",
    "       }\n",
    "       \n",
    "       feature_importance = pd.DataFrame({\n",
    "           'feature': data['X_train'].columns,\n",
    "           'importance': rf.feature_importances_\n",
    "       }).sort_values('importance', ascending=False)\n",
    "   \n",
    "   return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from 2021-02-02 00:00:00 to 2025-01-01 00:00:00\n",
      "Total symbols: 94\n",
      "Total trading days: 985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing pairs: 100%|██████████| 4371/4371 [00:52<00:00, 83.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis complete!\n",
      "Found 45 cointegrated pairs\n",
      "Total pairs analyzed: 4371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models: 100%|██████████| 45/45 [00:05<00:00,  8.07it/s]\n"
     ]
    }
   ],
   "source": [
    "price_matrix, symbols = load_and_prepare_data('../data/raw/nasdaq_daily.parquet')\n",
    "\n",
    "score_matrix, pvalue_matrix, cointegrated_pairs, coint_results = analyze_pairs(price_matrix)\n",
    "\n",
    "# plot_cointegration_heatmap(pvalue_matrix, symbols)\n",
    "\n",
    "returns, spreads = calculate_returns_and_spreads(price_matrix, cointegrated_pairs)\n",
    "\n",
    "train_period = get_training_period()\n",
    "test_period = get_test_period()\n",
    "\n",
    "ml_datasets = prepare_ml_data(returns, spreads, train_period, test_period)\n",
    "\n",
    "model_results = train_evaluate_models(ml_datasets, coint_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         pair        f1   p_value  weighted_score  accuracy  precision  \\\n",
      "30   ISRG_TTD  0.559387  0.003670        0.734164  0.543651   0.536765   \n",
      "32   KHC_MSFT  0.549020  0.009724        0.725522  0.543651   0.522388   \n",
      "4    ADSK_HON  0.547445  0.009983        0.724474  0.507937   0.576923   \n",
      "31   KDP_MNST  0.541176  0.000629        0.724454  0.535714   0.547619   \n",
      "27     EA_TTD  0.544715  0.006853        0.724088  0.555556   0.531746   \n",
      "5   AMAT_NXPI  0.539007  0.000091        0.723368  0.484127   0.503311   \n",
      "15   CSX_TTWO  0.539062  0.009163        0.719772  0.531746   0.543307   \n",
      "13    CSX_MDB  0.529183  0.009500        0.713710  0.519841   0.544000   \n",
      "28   GOOG_TTD  0.526718  0.007768        0.712923  0.507937   0.489362   \n",
      "37  LRCX_NXPI  0.521739  0.001418        0.712476  0.476190   0.483221   \n",
      "25    EA_NFLX  0.515873  0.002453        0.708543  0.515873   0.442177   \n",
      "8   CDNS_PCAR  0.517110  0.006162        0.707802  0.496032   0.496350   \n",
      "38   MAR_PANW  0.508475  0.000692        0.704808  0.539683   0.566038   \n",
      "39   MCHP_XEL  0.508197  0.005534        0.702704  0.523810   0.525424   \n",
      "17     CSX_ZS  0.504425  0.006336        0.700120  0.555556   0.518182   \n",
      "9     CDW_XEL  0.498141  0.001578        0.698254  0.464286   0.458904   \n",
      "29  GOOGL_TTD  0.500000  0.007324        0.697070  0.492063   0.477612   \n",
      "20     EA_HON  0.492188  0.004449        0.693533  0.484127   0.500000   \n",
      "44   TTD_VRSK  0.494024  0.007306        0.693492  0.496032   0.521008   \n",
      "3    ADI_PANW  0.493827  0.009833        0.692363  0.511905   0.495868   \n",
      "\n",
      "      recall  \n",
      "30  0.584000  \n",
      "32  0.578512  \n",
      "4   0.520833  \n",
      "31  0.534884  \n",
      "27  0.558333  \n",
      "5   0.580153  \n",
      "15  0.534884  \n",
      "13  0.515152  \n",
      "28  0.570248  \n",
      "37  0.566929  \n",
      "25  0.619048  \n",
      "8   0.539683  \n",
      "38  0.461538  \n",
      "39  0.492063  \n",
      "17  0.491379  \n",
      "9   0.544715  \n",
      "29  0.524590  \n",
      "20  0.484615  \n",
      "44  0.469697  \n",
      "3   0.491803  \n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame([\n",
    "   {\n",
    "       'pair': pair,\n",
    "       'accuracy': metrics['accuracy'],\n",
    "       'precision': metrics['precision'],\n",
    "       'recall': metrics['recall'],\n",
    "       'f1': metrics['f1'],\n",
    "       'p_value': metrics['p_value'],\n",
    "       'weighted_score': metrics['weighted_score']\n",
    "   }\n",
    "   for pair, metrics in model_results.items()\n",
    "])\n",
    "\n",
    "top_20 = results_df.sort_values('weighted_score', ascending=False).head(20)\n",
    "print(top_20[['pair', 'f1', 'p_value', 'weighted_score', 'accuracy', 'precision', 'recall']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(series):\n",
    "    return (series - series.mean()) / np.std(series)\n",
    "\n",
    "def calculate_spread(data, symbol1, symbol2, start_date=None, end_date=None):\n",
    "    if start_date:\n",
    "        mask = (data.index >= start_date) & (data.index <= end_date)\n",
    "        data = data[mask]\n",
    "    \n",
    "    # Calculate ratio and z-score\n",
    "    ratios = data[symbol1] / data[symbol2]\n",
    "    zscore_ratios = zscore(ratios)\n",
    "    \n",
    "    return ratios, zscore_ratios\n",
    "\n",
    "def trade(S1_train, S2_train, S1_test, S2_test, symbol1, symbol2, window1=5, window2=60):\n",
    "    ratios_train = S1_train / S2_train\n",
    "    ma2_train = ratios_train.rolling(window=window2, center=False).mean()\n",
    "    std_train = ratios_train.rolling(window=window2, center=False).std()\n",
    "    \n",
    "    ratios_test = S1_test / S2_test\n",
    "    trades = []\n",
    "    trade_id = 0\n",
    "    position = 0\n",
    "    entry_prices = None\n",
    "    entry_date = None\n",
    "    \n",
    "    for i in range(len(ratios_test)):\n",
    "        current_ratio = ratios_test.iloc[i]\n",
    "        current_date = ratios_test.index[i]\n",
    "        \n",
    "        ma2_test = ratios_test.iloc[:i+1].rolling(window=window2, center=False).mean().iloc[-1]\n",
    "        std_test = ratios_test.iloc[:i+1].rolling(window=window2, center=False).std().iloc[-1]\n",
    "        zscore = (current_ratio - ma2_test) / std_test\n",
    "        \n",
    "        if position == 0:\n",
    "            if zscore > 1.0:\n",
    "                entry_date = current_date\n",
    "                entry_prices = {\n",
    "                    symbol1: {\"price\": S1_test.iloc[i], \"type\": \"short\"},\n",
    "                    symbol2: {\"price\": S2_test.iloc[i], \"type\": \"long\"}\n",
    "                }\n",
    "                position = -1\n",
    "                \n",
    "            elif zscore < -1.0:\n",
    "                entry_date = current_date\n",
    "                entry_prices = {\n",
    "                    symbol1: {\"price\": S1_test.iloc[i], \"type\": \"long\"},\n",
    "                    symbol2: {\"price\": S2_test.iloc[i], \"type\": \"short\"}\n",
    "                }\n",
    "                position = 1\n",
    "                \n",
    "        elif abs(zscore) < 0.5 and position != 0:\n",
    "            for symbol in [symbol1, symbol2]:\n",
    "                trades.append({\n",
    "                    'trade_id': trade_id,\n",
    "                    'symbol': symbol,\n",
    "                    'entry_date': entry_date,\n",
    "                    'entry_price': entry_prices[symbol][\"price\"],\n",
    "                    'exit_date': current_date,\n",
    "                    'exit_price': S1_test.iloc[i] if symbol == symbol1 else S2_test.iloc[i],\n",
    "                    'position_type': entry_prices[symbol][\"type\"],\n",
    "                    'paired_symbol': symbol2 if symbol == symbol1 else symbol1,\n",
    "                    'exit_type': 'target'\n",
    "                })\n",
    "            position = 0\n",
    "            trade_id += 1\n",
    "            \n",
    "    return trades\n",
    "\n",
    "def backtest_pairs(price_matrix, pairs, train_end_date):\n",
    "    all_trades = []\n",
    "    \n",
    "    for symbol1, symbol2 in pairs:\n",
    "        training_mask = price_matrix.index < train_end_date\n",
    "        \n",
    "        S1_train = price_matrix[symbol1][training_mask]\n",
    "        S2_train = price_matrix[symbol2][training_mask]\n",
    "        S1_test = price_matrix[symbol1][~training_mask]\n",
    "        S2_test = price_matrix[symbol2][~training_mask]\n",
    "        \n",
    "        pair_trades = trade(S1_train, S2_train, S1_test, S2_test, symbol1, symbol2)\n",
    "        all_trades.extend(pair_trades)\n",
    "    \n",
    "    trades_df = pd.DataFrame(all_trades)\n",
    "    trades_df.to_parquet('../data/results/ranforest_zscore_results.parquet')\n",
    "    \n",
    "    return trades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '..data/results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m top_pairs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(pair\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m top_20[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpair\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m----> 3\u001b[0m trades_df \u001b[38;5;241m=\u001b[39m \u001b[43mbacktest_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprice_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_period\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBacktest Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal number of trades: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(trades_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[32], line 85\u001b[0m, in \u001b[0;36mbacktest_pairs\u001b[0;34m(price_matrix, pairs, train_end_date)\u001b[0m\n\u001b[1;32m     82\u001b[0m     all_trades\u001b[38;5;241m.\u001b[39mextend(pair_trades)\n\u001b[1;32m     84\u001b[0m trades_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_trades)\n\u001b[0;32m---> 85\u001b[0m \u001b[43mtrades_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m..data/results/ranforest_zscore_results.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trades_df\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py:3113\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   3032\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3033\u001b[0m \u001b[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[1;32m   3034\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3109\u001b[0m \u001b[38;5;124;03m>>> content = f.read()\u001b[39;00m\n\u001b[1;32m   3110\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[0;32m-> 3113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3121\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3122\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parquet.py:480\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[1;32m    478\u001b[0m path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[0;32m--> 480\u001b[0m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io\u001b[38;5;241m.\u001b[39mBytesIO)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parquet.py:198\u001b[0m, in \u001b[0;36mPyArrowImpl.write\u001b[0;34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     merged_metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexisting_metadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdf_metadata}\n\u001b[1;32m    196\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mreplace_schema_metadata(merged_metadata)\n\u001b[0;32m--> 198\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_cols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(path_or_handle, io\u001b[38;5;241m.\u001b[39mBufferedWriter)\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(path_or_handle, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_handle\u001b[38;5;241m.\u001b[39mname, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m))\n\u001b[1;32m    209\u001b[0m ):\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_handle\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mbytes\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parquet.py:140\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    130\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '..data/results'"
     ]
    }
   ],
   "source": [
    "top_pairs = [tuple(pair.split('_')) for pair in top_20['pair']]\n",
    "\n",
    "trades_df = backtest_pairs(price_matrix, top_pairs, train_period['end'])\n",
    "\n",
    "print(\"\\nBacktest Results:\")\n",
    "print(f\"Total number of trades: {len(trades_df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:20:56.897707Z",
     "start_time": "2025-03-06T10:20:55.406492Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install kneed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:20:57.366667Z",
     "start_time": "2025-03-06T10:20:56.901648Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from src.statistics.cointegration import find_cointegrated_pairs, analyze_pairs, plot_cointegration_heatmap\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import coint\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.cm as cm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Basic configuration\n",
    "DATE_CONFIG = {\n",
    "    'TRAIN_START': pd.Timestamp('2021-02-02'),\n",
    "    'TRAIN_END': pd.Timestamp('2024-01-01'),\n",
    "    'TEST_END': pd.Timestamp('2025-01-01'),\n",
    "    'TRADING_DAYS_PER_YEAR': 252  \n",
    "}\n",
    "\n",
    "def get_training_period():\n",
    "    return {\n",
    "        'start': DATE_CONFIG['TRAIN_START'],\n",
    "        'end': DATE_CONFIG['TRAIN_END']\n",
    "    }\n",
    "\n",
    "def get_test_period():\n",
    "    return {\n",
    "        'start': DATE_CONFIG['TRAIN_END'],\n",
    "        'end': DATE_CONFIG['TEST_END']\n",
    "    }\n",
    "\n",
    "def get_training_days():\n",
    "    years = (DATE_CONFIG['TRAIN_END'] - DATE_CONFIG['TRAIN_START']).days / 365\n",
    "    return int(years * DATE_CONFIG['TRADING_DAYS_PER_YEAR'])\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('classic')\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:20:57.439736Z",
     "start_time": "2025-03-06T10:20:57.437682Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "p_threshold = 0.05\n",
    "min_pairs = 20\n",
    "\n",
    "window_shifts = 12\n",
    "shift_size = 1\n",
    "\n",
    "std_dev = 2\n",
    "exit_std_dev = 0.5\n",
    "window = 50\n",
    "hr_window = 25\n",
    "hr_recalc = 3\n",
    "\n",
    "preference = None  \n",
    "\n",
    "base_input_path = \"../../data/raw/\" \n",
    "input_filename = \"nasdaq_daily.parquet\" \n",
    "base_output_path = \"../../data/results/\" \n",
    "output_filename = \"Cluster_Bollinger_Sliding.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:20:57.447911Z",
     "start_time": "2025-03-06T10:20:57.445749Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    mask = (df['date'] >= DATE_CONFIG['TRAIN_START']) & (df['date'] <= DATE_CONFIG['TEST_END'])\n",
    "    df = df[mask]\n",
    "    \n",
    "    price_matrix = df.pivot(index='date', columns='symbol', values='close')\n",
    "    \n",
    "    price_matrix = price_matrix.ffill().bfill()\n",
    "    \n",
    "    symbols = price_matrix.columns.tolist()\n",
    "    \n",
    "    print(f\"Loaded data from {DATE_CONFIG['TRAIN_START']} to {DATE_CONFIG['TEST_END']}\")\n",
    "    print(f\"Total symbols: {len(symbols)}\")\n",
    "    print(f\"Total trading days: {len(price_matrix)}\")\n",
    "    \n",
    "    return price_matrix, symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loade Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:20:57.513928Z",
     "start_time": "2025-03-06T10:20:57.455497Z"
    }
   },
   "outputs": [],
   "source": [
    "input_data_path = f\"{base_input_path}{input_filename}\"\n",
    "output_path = f\"{base_output_path}{output_filename}\"\n",
    "\n",
    "price_matrix, symbols = load_and_prepare_data(input_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$ \\text{Rendite} = \\frac{1}{T} \\sum_{t=1}^{T} \\frac{P_t - P_{t-1}}{P_{t-1}} \\times \\text{Trading days per year} $$\n",
    "\n",
    "\n",
    "$$ \\text{VolatilitÃ¤t} = \\sqrt{\\frac{1}{T-1} \\sum_{t=1}^{T} \\left( \\frac{P_t - P_{t-1}}{P_{t-1}} - \\mu \\right)^2} \\times \\sqrt{\\text{Trading days per year}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:20:57.522551Z",
     "start_time": "2025-03-06T10:20:57.520751Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(price_matrix):\n",
    "    returns = price_matrix.pct_change().mean() * DATE_CONFIG['TRADING_DAYS_PER_YEAR']\n",
    "    metrics = pd.DataFrame(returns, columns=['returns'])\n",
    "    metrics['volatility'] = price_matrix.pct_change().std() * np.sqrt(DATE_CONFIG['TRADING_DAYS_PER_YEAR'])\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:20:57.540561Z",
     "start_time": "2025-03-06T10:20:57.528831Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = calculate_metrics(price_matrix)\n",
    "print(\"Erste 5 Zeilen der Metriken:\")\n",
    "print(metrics.head())\n",
    "print(\"\\nBeschreibung der Metriken:\")\n",
    "print(metrics.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scale Transform\n",
    "The StandardScaler transforms our features (returns and volatility) to have zero mean and unit variance, which eliminates the scale difference between our variables and prevents higher magnitude features from dominating. This standardization is crucial for many machine learning algorithms as it ensures that all features contribute equally to the model and helps prevent numerical instabilities during the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:20:57.548540Z",
     "start_time": "2025-03-06T10:20:57.546814Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale_metrics(metrics):\n",
    "    scaler = StandardScaler()\n",
    "    scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(metrics),\n",
    "        columns=metrics.columns,\n",
    "        index=metrics.index\n",
    "    )\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:20:57.560046Z",
     "start_time": "2025-03-06T10:20:57.554606Z"
    }
   },
   "outputs": [],
   "source": [
    "X = scale_metrics(metrics)\n",
    "print(\"Erste 5 Zeilen der skalierten Daten:\")\n",
    "print(X.head())\n",
    "print(\"\\nBeschreibung der skalierten Daten:\")\n",
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affinity Propagation Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:20:57.688094Z",
     "start_time": "2025-03-06T10:20:57.566852Z"
    }
   },
   "outputs": [],
   "source": [
    "if preference is None:\n",
    "    ap = AffinityPropagation()\n",
    "else:\n",
    "    ap = AffinityPropagation(preference=preference)\n",
    "ap.fit(X)\n",
    "labels1 = ap.predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot(111)\n",
    "scatter = ax.scatter(X.iloc[:,0], X.iloc[:,1], c=labels1, cmap='rainbow')\n",
    "ax.set_title('Affinity Propagation Clustering Results')\n",
    "ax.set_xlabel('Mean Return')\n",
    "ax.set_ylabel('Volatility')\n",
    "plt.colorbar(scatter)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:20:57.702355Z",
     "start_time": "2025-03-06T10:20:57.696634Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_pairs(X, ap, price_matrix, min_pairs=min_pairs, p_threshold=p_threshold):\n",
    "    scores = []\n",
    "    \n",
    "    for cluster_id in np.unique(ap.labels_):\n",
    "        cluster_mask = ap.labels_ == cluster_id\n",
    "        cluster_symbols = X.index[cluster_mask]\n",
    "        center = X.iloc[ap.cluster_centers_indices_[cluster_id]]\n",
    "        \n",
    "        for i in range(len(cluster_symbols)):\n",
    "            for j in range(i+1, len(cluster_symbols)):\n",
    "                symbol1, symbol2 = cluster_symbols[i], cluster_symbols[j]\n",
    "                \n",
    "                dist1 = np.linalg.norm(X.loc[symbol1] - center)\n",
    "                dist2 = np.linalg.norm(X.loc[symbol2] - center)\n",
    "                center_dist = (dist1 + dist2) / 2\n",
    "                \n",
    "                profile_diff = np.linalg.norm(X.loc[symbol1] - X.loc[symbol2])\n",
    "                \n",
    "                series1 = price_matrix[symbol1]\n",
    "                series2 = price_matrix[symbol2]\n",
    "                score, pvalue, _ = coint(series1, series2)\n",
    "                \n",
    "                if pvalue < p_threshold:\n",
    "                    scores.append({\n",
    "                        'pair': (symbol1, symbol2),\n",
    "                        'center_dist': center_dist,\n",
    "                        'profile_diff': profile_diff,\n",
    "                        'pvalue': pvalue,\n",
    "                        'cluster': cluster_id\n",
    "                    })\n",
    "\n",
    "    scores_df = pd.DataFrame(scores)\n",
    "    \n",
    "    # ÃberprÃ¼fen, ob die DataFrame leer ist\n",
    "    if len(scores_df) == 0:\n",
    "        print(f\"Keine cointegrierten Paare mit p-value < {p_threshold} gefunden.\")\n",
    "        return [], pd.DataFrame()\n",
    "\n",
    "    scores_df['center_dist_norm'] = (scores_df['center_dist'] - scores_df['center_dist'].min()) / \\\n",
    "                                   (scores_df['center_dist'].max() - scores_df['center_dist'].min())\n",
    "    scores_df['profile_diff_norm'] = (scores_df['profile_diff'] - scores_df['profile_diff'].min()) / \\\n",
    "                                    (scores_df['profile_diff'].max() - scores_df['profile_diff'].min())\n",
    "\n",
    "    scores_df['combined_score'] = 0.6 * scores_df['center_dist_norm'] + \\\n",
    "                                 0.4 * scores_df['profile_diff_norm']\n",
    "    \n",
    "    scores_df = scores_df.sort_values('combined_score')\n",
    "    \n",
    "    while len(scores_df) < min_pairs and p_threshold < 0.1:\n",
    "        p_threshold += 0.05\n",
    "        scores = []\n",
    "        for cluster_id in np.unique(ap.labels_):\n",
    "            cluster_mask = ap.labels_ == cluster_id\n",
    "            cluster_symbols = X.index[cluster_mask]\n",
    "            center = X.iloc[ap.cluster_centers_indices_[cluster_id]]\n",
    "            \n",
    "            for i in range(len(cluster_symbols)):\n",
    "                for j in range(i+1, len(cluster_symbols)):\n",
    "                    symbol1, symbol2 = cluster_symbols[i], cluster_symbols[j]\n",
    "                    dist1 = np.linalg.norm(X.loc[symbol1] - center)\n",
    "                    dist2 = np.linalg.norm(X.loc[symbol2] - center)\n",
    "                    center_dist = (dist1 + dist2) / 2\n",
    "                    profile_diff = np.linalg.norm(X.loc[symbol1] - X.loc[symbol2])\n",
    "                    score, pvalue, _ = coint(series1, series2)\n",
    "                    \n",
    "                    if pvalue < p_threshold:\n",
    "                        scores.append({\n",
    "                            'pair': (symbol1, symbol2),\n",
    "                            'center_dist': center_dist,\n",
    "                            'profile_diff': profile_diff,\n",
    "                            'pvalue': pvalue,\n",
    "                            'cluster': cluster_id\n",
    "                        })\n",
    "        \n",
    "        scores_df = pd.DataFrame(scores)\n",
    "        if len(scores) > 0:\n",
    "            scores_df['center_dist_norm'] = (scores_df['center_dist'] - scores_df['center_dist'].min()) / \\\n",
    "                                          (scores_df['center_dist'].max() - scores_df['center_dist'].min())\n",
    "            scores_df['profile_diff_norm'] = (scores_df['profile_diff'] - scores_df['profile_diff'].min()) / \\\n",
    "                                           (scores_df['profile_diff'].max() - scores_df['profile_diff'].min())\n",
    "            scores_df['combined_score'] = 0.6 * scores_df['center_dist_norm'] + \\\n",
    "                                        0.4 * scores_df['profile_diff_norm']\n",
    "            scores_df = scores_df.sort_values('combined_score')\n",
    "    \n",
    "    num_pairs = min(len(scores_df), min_pairs)\n",
    "    print(f\"Found {len(scores_df)} pairs with p-value < {p_threshold}\")\n",
    "    return scores_df['pair'].tolist()[:num_pairs], scores_df[:num_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:21:16.854775Z",
     "start_time": "2025-03-06T10:20:57.715939Z"
    }
   },
   "outputs": [],
   "source": [
    "top_pairs, scores_df = get_top_pairs(X, ap, price_matrix, min_pairs=20)\n",
    "\n",
    "print(\"\\nTop pairs details:\")\n",
    "if not scores_df.empty:\n",
    "    print(scores_df[['pair', 'center_dist', 'profile_diff', 'pvalue', 'combined_score', 'cluster']])\n",
    "else:\n",
    "    print(\"Keine Paare gefunden.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:21:16.980602Z",
     "start_time": "2025-03-06T10:21:16.858724Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "#Extract the cluster centers and labels\n",
    "cci = ap.cluster_centers_indices_\n",
    "labels2 = ap.labels_\n",
    "\n",
    "#Print their number\n",
    "clusters = len(cci)\n",
    "print('The number of clusters is:',clusters)\n",
    "\n",
    "#Plot the results\n",
    "X_ap = np.asarray(X)\n",
    "plt.close('all')\n",
    "plt.figure(1)\n",
    "plt.clf\n",
    "fig=plt.figure(figsize=(15,10))\n",
    "colors = cycle('cmykrgbcmykrgbcmykrgbcmykrgb')\n",
    "for k, col in zip(range(clusters),colors):\n",
    "    cluster_members = labels2 == k\n",
    "    cluster_center = X_ap[cci[k]]\n",
    "    plt.plot(X_ap[cluster_members, 0], X_ap[cluster_members, 1], col + '.')\n",
    "    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col, markeredgecolor='k', markersize=12)\n",
    "    for x in X_ap[cluster_members]:\n",
    "        plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\n",
    "\n",
    "plt.title('Affinity Propagation Clustering Results with Connections')\n",
    "plt.xlabel('Mean Return')\n",
    "plt.ylabel('Volatility')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:21:16.992845Z",
     "start_time": "2025-03-06T10:21:16.990257Z"
    }
   },
   "outputs": [],
   "source": [
    "clustered_series_ap = pd.Series(index=X.index, data=ap.labels_.flatten())\n",
    "\n",
    "cluster_size_limit = 1000\n",
    "counts = clustered_series_ap.value_counts()\n",
    "ticker_count = counts[(counts>1) & (counts<=cluster_size_limit)]\n",
    "print(\"Number of clusters:\", len(ticker_count))\n",
    "print(\"Number of Pairs:\", (ticker_count*(ticker_count-1)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:21:36.725681Z",
     "start_time": "2025-03-06T10:21:17.002087Z"
    }
   },
   "outputs": [],
   "source": [
    "all_pairs_with_clusters = []\n",
    "\n",
    "for cluster_id in np.unique(ap.labels_):\n",
    "    cluster_mask = ap.labels_ == cluster_id\n",
    "    cluster_symbols = X.index[cluster_mask]\n",
    "    \n",
    "    if len(cluster_symbols) > 1:\n",
    "        cluster_prices = price_matrix[cluster_symbols]\n",
    "        score_matrix, pvalue_matrix, pairs, _ = analyze_pairs(\n",
    "            cluster_prices,\n",
    "            pvalue_threshold=0.05\n",
    "        )\n",
    "        \n",
    "        if len(pairs) > 0:\n",
    "            for pair in pairs:\n",
    "                all_pairs_with_clusters.append({\n",
    "                    'pair': pair,\n",
    "                    'cluster': cluster_id\n",
    "                })\n",
    "            print(f\"\\nCluster {cluster_id} pairs:\")\n",
    "            for pair in pairs:\n",
    "                print(f\"{pair[0]} - {pair[1]}\")\n",
    "                \n",
    "            plot_cointegration_heatmap(pvalue_matrix, cluster_symbols)\n",
    "\n",
    "all_pairs = [item['pair'] for item in all_pairs_with_clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:21:36.743191Z",
     "start_time": "2025-03-06T10:21:36.740515Z"
    }
   },
   "outputs": [],
   "source": [
    "stocks = np.unique([stock for pair in top_pairs for stock in pair])\n",
    "X_data = pd.DataFrame(index=X.index, data=X).T  \n",
    "in_pairs_series = pd.Series(index=stocks, data=[ap.labels_[list(X.index).index(stock)] for stock in stocks])\n",
    "X_pairs = X_data.T.loc[stocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:21:36.925987Z",
     "start_time": "2025-03-06T10:21:36.759944Z"
    }
   },
   "outputs": [],
   "source": [
    "X_tsne = TSNE(learning_rate=30, perplexity=5, random_state=42, n_jobs=-1).fit_transform(X_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:21:37.143064Z",
     "start_time": "2025-03-06T10:21:36.944800Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12), facecolor='white')\n",
    "plt.clf()\n",
    "plt.gca().set_facecolor('#f8f9fa')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "for pair in top_pairs:\n",
    "    cluster = scores_df[scores_df['pair'] == pair]['cluster'].values[0]\n",
    "    loc1 = X_pairs.index.get_loc(pair[0])\n",
    "    loc2 = X_pairs.index.get_loc(pair[1])\n",
    "    x1, y1 = X_tsne[loc1, :]\n",
    "    x2, y2 = X_tsne[loc2, :]\n",
    "    plt.plot([x1, x2], [y1, y2], '-', alpha=0.4, linewidth=1.5, color='#4a90e2')\n",
    "\n",
    "scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], \n",
    "                     s=300,\n",
    "                     alpha=0.7,\n",
    "                     c=in_pairs_series.values,\n",
    "                     cmap='tab20',\n",
    "                     edgecolor='white',\n",
    "                     linewidth=2)\n",
    "\n",
    "for x, y, name in zip(X_tsne[:,0], X_tsne[:,1], X_pairs.index):\n",
    "    plt.annotate(name,\n",
    "                (x,y),\n",
    "                textcoords=\"offset points\",\n",
    "                xytext=(0,10),\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                fontsize=11,\n",
    "                fontweight='bold',\n",
    "                bbox=dict(facecolor='white', \n",
    "                         edgecolor='none',\n",
    "                         alpha=0.7,\n",
    "                         pad=1))\n",
    "\n",
    "plt.title('Stock Pairs Clustering Visualization (Same Cluster Only)', \n",
    "          fontsize=16, \n",
    "          pad=20,\n",
    "          fontweight='bold')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:21:37.165706Z",
     "start_time": "2025-03-06T10:21:37.159856Z"
    }
   },
   "outputs": [],
   "source": [
    "def trade(S1_train, S2_train, S1_test, S2_test, symbol1, symbol2, window_number, window=window, hr_window=hr_window, hr_recalc=hr_recalc, std_dev=std_dev, exit_std_dev=exit_std_dev):\n",
    "    trades = []\n",
    "    trade_id = 0\n",
    "    active_trades = []  \n",
    "    \n",
    "    S1_full = pd.concat([S1_train, S1_test])\n",
    "    S2_full = pd.concat([S2_train, S2_test])\n",
    "    \n",
    "    days_since_recalc = 0\n",
    "    current_hedge_ratio = None\n",
    "    \n",
    "    for i in range(len(S1_test)):\n",
    "        current_idx = S1_train.shape[0] + i\n",
    "        current_date = S1_test.index[i]\n",
    "        \n",
    "        if days_since_recalc >= hr_recalc or current_hedge_ratio is None:\n",
    "            if current_idx >= hr_window:\n",
    "                hr_data_1 = S1_full.iloc[current_idx-hr_window:current_idx]\n",
    "                hr_data_2 = S2_full.iloc[current_idx-hr_window:current_idx]\n",
    "                model = sm.OLS(hr_data_1, hr_data_2)\n",
    "                current_hedge_ratio = model.fit().params[0]\n",
    "                days_since_recalc = 0\n",
    "        \n",
    "        days_since_recalc += 1\n",
    "        \n",
    "        if current_hedge_ratio is None:\n",
    "            continue\n",
    "            \n",
    "        spread_full = S1_full - (S2_full * current_hedge_ratio)\n",
    "        spread_window = spread_full.iloc[:current_idx+1]\n",
    "        \n",
    "        if len(spread_window) < window:\n",
    "            continue\n",
    "            \n",
    "        rolling_mean = spread_window.rolling(window=window).mean().iloc[-1]\n",
    "        rolling_std = spread_window.rolling(window=window).std().iloc[-1]\n",
    "        \n",
    "        if pd.isna(rolling_std) or rolling_std == 0:\n",
    "            continue\n",
    "            \n",
    "        upper_band = rolling_mean + (rolling_std * std_dev)\n",
    "        lower_band = rolling_mean - (rolling_std * std_dev)\n",
    "        \n",
    "        current_spread = spread_full.iloc[current_idx]\n",
    "\n",
    "        if current_spread > upper_band:\n",
    "            trade_entry = {\n",
    "                'trade_id': trade_id,\n",
    "                'symbol1': symbol1,\n",
    "                'symbol2': symbol2,\n",
    "                'entry_date': current_date,\n",
    "                'type': 'short',\n",
    "                'status': 'active',\n",
    "                'entry_prices': {\n",
    "                    symbol1: {'price': S1_test.iloc[i], 'type': 'short'},\n",
    "                    symbol2: {'price': S2_test.iloc[i], 'type': 'long'}\n",
    "                },\n",
    "                'hedge_ratio': current_hedge_ratio,\n",
    "                'window': window_number\n",
    "            }\n",
    "            active_trades.append(trade_entry)\n",
    "            trade_id += 1\n",
    "            \n",
    "        elif current_spread < lower_band:\n",
    "            trade_entry = {\n",
    "                'trade_id': trade_id,\n",
    "                'symbol1': symbol1,\n",
    "                'symbol2': symbol2,\n",
    "                'entry_date': current_date,\n",
    "                'type': 'long', \n",
    "                'status': 'active',\n",
    "                'entry_prices': {\n",
    "                    symbol1: {'price': S1_test.iloc[i], 'type': 'long'},\n",
    "                    symbol2: {'price': S2_test.iloc[i], 'type': 'short'}\n",
    "                },\n",
    "                'hedge_ratio': current_hedge_ratio,\n",
    "                'window': window_number\n",
    "            }\n",
    "            active_trades.append(trade_entry)\n",
    "            trade_id += 1\n",
    "\n",
    "        for trade in active_trades:\n",
    "            if trade['status'] == 'active':\n",
    "\n",
    "                upper_exit = rolling_mean + (rolling_std * exit_std_dev)\n",
    "                lower_exit = rolling_mean - (rolling_std * exit_std_dev)\n",
    "\n",
    "                if (trade['type'] == 'short' and current_spread < upper_exit and current_spread > lower_exit) or \\\n",
    "                   (trade['type'] == 'long' and current_spread < upper_exit and current_spread > lower_exit):\n",
    "                    \n",
    "                    trade['status'] = 'closed'\n",
    "                    \n",
    "                    for symbol in [symbol1, symbol2]:\n",
    "                        trades.append({\n",
    "                            'trade_id': trade['trade_id'],\n",
    "                            'symbol': symbol,\n",
    "                            'entry_date': trade['entry_date'],\n",
    "                            'entry_price': trade['entry_prices'][symbol]['price'],\n",
    "                            'exit_date': current_date,\n",
    "                            'exit_price': S1_test.iloc[i] if symbol == symbol1 else S2_test.iloc[i],\n",
    "                            'position_type': trade['entry_prices'][symbol]['type'],\n",
    "                            'paired_symbol': symbol2 if symbol == symbol1 else symbol1,\n",
    "                            'exit_type': 'target',\n",
    "                            'window': trade['window'],\n",
    "                            'hedge_ratio': trade['hedge_ratio']\n",
    "                        })\n",
    "\n",
    "    active_trades = [t for t in active_trades if t['status'] == 'active']\n",
    "    return trades, active_trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:21:37.184004Z",
     "start_time": "2025-03-06T10:21:37.182026Z"
    }
   },
   "outputs": [],
   "source": [
    "def zscore(series):\n",
    "    return (series - series.mean()) / np.std(series)\n",
    "\n",
    "def calculate_spread(data, symbol1, symbol2, start_date=None, end_date=None):\n",
    "    if start_date:\n",
    "        mask = (data.index >= start_date) & (data.index <= end_date)\n",
    "        data = data[mask]\n",
    "    \n",
    "    ratios = data[symbol1] / data[symbol2]\n",
    "    zscore_ratios = zscore(ratios)\n",
    "    \n",
    "    return ratios, zscore_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:21:37.210789Z",
     "start_time": "2025-03-06T10:21:37.200208Z"
    }
   },
   "outputs": [],
   "source": [
    "def backtest_pairs_sliding(price_matrix, initial_start_date, initial_end_date, base_output_path, output_filename, window_shifts=window_shifts, p_threshold=p_threshold, shift_size=shift_size):\n",
    "    all_trades = []\n",
    "    ongoing_trades = []\n",
    "    \n",
    "    print(f\"Price Matrix Zeitraum: {price_matrix.index.min()} bis {price_matrix.index.max()}\")\n",
    "    \n",
    "    for window_number in range(window_shifts):\n",
    "        current_start = initial_start_date + pd.DateOffset(months=window_number*shift_size)\n",
    "        current_end = initial_end_date + pd.DateOffset(months=window_number*shift_size)\n",
    "        \n",
    "        print(f\"\\nAnalyse {window_number+1}/{window_shifts}\")\n",
    "        print(f\"Cluster-Fenster: {current_start} bis {current_end}\")\n",
    "        \n",
    "        cluster_data = price_matrix[(price_matrix.index >= current_start) & \n",
    "                                  (price_matrix.index <= current_end)].copy()\n",
    "        \n",
    "        if len(cluster_data) == 0:\n",
    "            print(f\"Keine Daten fÃ¼r Fenster {window_number+1}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Cluster Daten: {len(cluster_data)} Tage\")\n",
    "            \n",
    "        metrics = calculate_metrics(cluster_data)\n",
    "        X = scale_metrics(metrics)\n",
    "        \n",
    "        if preference is None:\n",
    "            ap = AffinityPropagation()\n",
    "        else:\n",
    "            ap = AffinityPropagation(preference=preference)\n",
    "        ap.fit(X)\n",
    "        \n",
    "        # Zeige die Anzahl der Cluster an\n",
    "        print(f\"Anzahl der erzeugten Cluster: {len(np.unique(ap.labels_))}\")\n",
    "        \n",
    "        potential_pairs = []\n",
    "        \n",
    "        for cluster_id in np.unique(ap.labels_):\n",
    "            cluster_mask = ap.labels_ == cluster_id\n",
    "            cluster_symbols = X.index[cluster_mask]\n",
    "            center = X.iloc[ap.cluster_centers_indices_[cluster_id]]\n",
    "            \n",
    "            for i in range(len(cluster_symbols)):\n",
    "                for j in range(i+1, len(cluster_symbols)):\n",
    "                    symbol1, symbol2 = cluster_symbols[i], cluster_symbols[j]\n",
    "                    \n",
    "                    dist1 = np.linalg.norm(X.loc[symbol1] - center)\n",
    "                    dist2 = np.linalg.norm(X.loc[symbol2] - center)\n",
    "                    center_dist = (dist1 + dist2) / 2\n",
    "                    profile_diff = np.linalg.norm(X.loc[symbol1] - X.loc[symbol2])\n",
    "                    \n",
    "                    s1 = cluster_data[symbol1].dropna()\n",
    "                    s2 = cluster_data[symbol2].dropna()\n",
    "                    \n",
    "                    if len(s1) > 0 and len(s2) > 0:\n",
    "                        try:\n",
    "                            score, pvalue, _ = coint(s1, s2)\n",
    "                            \n",
    "                            if pvalue < p_threshold:\n",
    "                                potential_pairs.append({\n",
    "                                    'pair': (symbol1, symbol2),\n",
    "                                    'center_dist': center_dist,\n",
    "                                    'profile_diff': profile_diff,\n",
    "                                    'pvalue': pvalue,\n",
    "                                    'cluster': cluster_id\n",
    "                                })\n",
    "                        except:\n",
    "                            continue\n",
    "        \n",
    "        if not potential_pairs:\n",
    "            print(f\"Keine cointegrierten Paare gefunden fÃ¼r Fenster {window_number+1}\")\n",
    "            continue\n",
    "            \n",
    "        pairs_df = pd.DataFrame(potential_pairs)\n",
    "        \n",
    "        pairs_df['center_dist_norm'] = (pairs_df['center_dist'] - pairs_df['center_dist'].min()) / \\\n",
    "                                     (pairs_df['center_dist'].max() - pairs_df['center_dist'].min())\n",
    "        pairs_df['profile_diff_norm'] = (pairs_df['profile_diff'] - pairs_df['profile_diff'].min()) / \\\n",
    "                                      (pairs_df['profile_diff'].max() - pairs_df['profile_diff'].min())\n",
    "        \n",
    "        pairs_df['combined_score'] = 0.6 * pairs_df['center_dist_norm'] + \\\n",
    "                                   0.4 * pairs_df['profile_diff_norm']\n",
    "        \n",
    "        pairs_df = pairs_df.sort_values('combined_score')\n",
    "        top_pairs = pairs_df['pair'].tolist()[:min_pairs]\n",
    "        \n",
    "        print(f\"Gefundene cointegrierte Paare fÃ¼r Fenster {window_number+1}: {len(top_pairs)}\")\n",
    "        \n",
    "        trade_start = current_end\n",
    "        trade_end = trade_start + pd.DateOffset(months=1)\n",
    "        \n",
    "        print(f\"Trading-Zeitraum: {trade_start} bis {trade_end}\")\n",
    "        \n",
    "        trading_data = price_matrix[(price_matrix.index > trade_start) & \n",
    "                                  (price_matrix.index <= trade_end)].copy()\n",
    "        \n",
    "        print(f\"Trading Daten: {len(trading_data)} Tage\")\n",
    "        \n",
    "        if len(trading_data) == 0:\n",
    "            print(f\"Warnung: Kein Trading-Zeitraum verfÃ¼gbar nach {trade_start}\")\n",
    "            continue\n",
    "        \n",
    "        # Bestehende Trades Ã¼berprÃ¼fen und ggf. schlieÃen\n",
    "        updated_ongoing_trades = []\n",
    "        closed_trade_ids = set()\n",
    "        \n",
    "        for open_trade in ongoing_trades:\n",
    "            symbol1, symbol2 = open_trade['symbol1'], open_trade['symbol2']\n",
    "            \n",
    "            if symbol1 in trading_data.columns and symbol2 in trading_data.columns:\n",
    "                still_active = True\n",
    "                \n",
    "                for idx, date in enumerate(trading_data.index):\n",
    "                    # Hedge Ratio aus dem offenen Trade nehmen\n",
    "                    current_hedge_ratio = open_trade['hedge_ratio']\n",
    "                    \n",
    "                    if pd.isna(current_hedge_ratio) or current_hedge_ratio is None:\n",
    "                        continue\n",
    "                    \n",
    "                    # Historische Daten bis zum Entry Datum verwenden\n",
    "                    hist_data = price_matrix[(price_matrix.index <= open_trade['entry_date'])]\n",
    "                    \n",
    "                    if len(hist_data) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    # Spread berechnen fÃ¼r historische Daten\n",
    "                    spread_hist = hist_data[symbol1] - (hist_data[symbol2] * current_hedge_ratio)\n",
    "                    \n",
    "                    if len(spread_hist) < window:\n",
    "                        continue\n",
    "                    \n",
    "                    # Statistische Werte berechnen\n",
    "                    rolling_mean = spread_hist.rolling(window=window).mean().iloc[-1]\n",
    "                    rolling_std = spread_hist.rolling(window=window).std().iloc[-1]\n",
    "                    \n",
    "                    if pd.isna(rolling_std) or rolling_std == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    # Exit-BÃ¤nder festlegen\n",
    "                    upper_exit = rolling_mean + (rolling_std * exit_std_dev)\n",
    "                    lower_exit = rolling_mean - (rolling_std * exit_std_dev)\n",
    "                    \n",
    "                    # Aktuellen Spread berechnen\n",
    "                    current_spread = trading_data[symbol1].iloc[idx] - (trading_data[symbol2].iloc[idx] * current_hedge_ratio)\n",
    "                    \n",
    "                    # Exit-Bedingung prÃ¼fen\n",
    "                    if (open_trade['type'] == 'short' and current_spread < upper_exit and current_spread > lower_exit) or \\\n",
    "                       (open_trade['type'] == 'long' and current_spread < upper_exit and current_spread > lower_exit):\n",
    "                        \n",
    "                        open_trade['status'] = 'closed'\n",
    "                        closed_trade_ids.add(open_trade['trade_id'])\n",
    "                        \n",
    "                        for symbol in [symbol1, symbol2]:\n",
    "                            all_trades.append({\n",
    "                                'trade_id': open_trade['trade_id'],\n",
    "                                'symbol': symbol,\n",
    "                                'entry_date': open_trade['entry_date'],\n",
    "                                'entry_price': open_trade['entry_prices'][symbol]['price'],\n",
    "                                'exit_date': date,\n",
    "                                'exit_price': trading_data.loc[date, symbol],\n",
    "                                'position_type': open_trade['entry_prices'][symbol]['type'],\n",
    "                                'paired_symbol': symbol2 if symbol == symbol1 else symbol1,\n",
    "                                'exit_type': 'target',\n",
    "                                'window': open_trade['window'],\n",
    "                                'hedge_ratio': open_trade['hedge_ratio']\n",
    "                            })\n",
    "                        \n",
    "                        still_active = False\n",
    "                        break\n",
    "                \n",
    "                if still_active:\n",
    "                    updated_ongoing_trades.append(open_trade)\n",
    "        \n",
    "        ongoing_trades = updated_ongoing_trades\n",
    "        \n",
    "        # Neue Trades generieren\n",
    "        trade_count = 0\n",
    "        for pair in top_pairs:\n",
    "            symbol1, symbol2 = pair\n",
    "            \n",
    "            # Get clean segments for trading\n",
    "            train_s1 = cluster_data[symbol1].dropna()\n",
    "            train_s2 = cluster_data[symbol2].dropna() \n",
    "            test_s1 = trading_data[symbol1].dropna()\n",
    "            test_s2 = trading_data[symbol2].dropna()\n",
    "            \n",
    "            if len(train_s1) == 0 or len(train_s2) == 0 or len(test_s1) == 0 or len(test_s2) == 0:\n",
    "                continue\n",
    "            \n",
    "            new_trades, active_new_trades = trade(\n",
    "                train_s1, \n",
    "                train_s2,\n",
    "                test_s1, \n",
    "                test_s2,\n",
    "                symbol1, symbol2,\n",
    "                window_number=window_number + 1\n",
    "            )\n",
    "            \n",
    "            if new_trades:\n",
    "                trade_count += len(new_trades)\n",
    "                all_trades.extend(new_trades)\n",
    "            \n",
    "            ongoing_trades.extend(active_new_trades)\n",
    "        \n",
    "        print(f\"Neue geschlossene Trades in diesem Fenster: {trade_count}\")\n",
    "        print(f\"Aktuell offene Trades: {len(ongoing_trades)}\")\n",
    "    \n",
    "    trades_df = pd.DataFrame(all_trades)\n",
    "    \n",
    "    if len(trades_df) > 0:\n",
    "        full_output_path = f\"{base_output_path}{output_filename}\"\n",
    "        trades_df.to_parquet(full_output_path)\n",
    "        \n",
    "        print(\"\\nTrading Zusammenfassung:\")\n",
    "        print(f\"Gesamtanzahl Trades: {len(trades_df)}\")\n",
    "        print(f\"Unique Paare gehandelt: {len(trades_df[['symbol', 'paired_symbol']].drop_duplicates())}\")\n",
    "        print(f\"Zeitraum: {trades_df['entry_date'].min()} bis {trades_df['exit_date'].max()}\")\n",
    "        \n",
    "        print(\"\\nTrades pro Fenster:\")\n",
    "        print(trades_df['window'].value_counts().sort_index())\n",
    "    else:\n",
    "        print(\"Keine Trades generiert!\")\n",
    "        \n",
    "    return trades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:25:24.641314Z",
     "start_time": "2025-03-06T10:21:37.227525Z"
    }
   },
   "outputs": [],
   "source": [
    "trades_df = backtest_pairs_sliding(\n",
    "    price_matrix=price_matrix,\n",
    "    initial_start_date=DATE_CONFIG['TRAIN_START'],\n",
    "    initial_end_date=DATE_CONFIG['TRAIN_END'], \n",
    "    base_output_path=base_output_path,\n",
    "    output_filename=output_filename\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

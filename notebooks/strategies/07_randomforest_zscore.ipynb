{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from src.analysis.cointegration import find_cointegrated_pairs, analyze_pairs, plot_cointegration_heatmap\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import coint\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATE_CONFIG = {\n",
    "    'TRAIN_START': pd.Timestamp('2021-02-02'),\n",
    "    'TRAIN_END': pd.Timestamp('2024-01-01'),\n",
    "    'TEST_END': pd.Timestamp('2025-01-01'),\n",
    "    'TRADING_DAYS_PER_YEAR': 252  \n",
    "}\n",
    "\n",
    "def get_training_period():\n",
    "    return {\n",
    "        'start': DATE_CONFIG['TRAIN_START'],\n",
    "        'end': DATE_CONFIG['TRAIN_END']\n",
    "    }\n",
    "\n",
    "def get_test_period():\n",
    "    return {\n",
    "        'start': DATE_CONFIG['TRAIN_END'],\n",
    "        'end': DATE_CONFIG['TEST_END']\n",
    "    }\n",
    "\n",
    "def get_training_days():\n",
    "    years = (DATE_CONFIG['TRAIN_END'] - DATE_CONFIG['TRAIN_START']).days / 365\n",
    "    return int(years * DATE_CONFIG['TRADING_DAYS_PER_YEAR'])\n",
    "\n",
    "plt.style.use('classic')\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path):\n",
    "\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    mask = (df['date'] >= DATE_CONFIG['TRAIN_START']) & \\\n",
    "           (df['date'] <= DATE_CONFIG['TEST_END'])\n",
    "    df = df[mask]\n",
    "    \n",
    "    price_matrix = df.pivot(index='date', columns='symbol', values='close')\n",
    "    \n",
    "    symbols = price_matrix.columns.tolist()\n",
    "    \n",
    "    print(f\"Loaded data from {DATE_CONFIG['TRAIN_START']} to {DATE_CONFIG['TEST_END']}\")\n",
    "    print(f\"Total symbols: {len(symbols)}\")\n",
    "    print(f\"Total trading days: {len(price_matrix)}\")\n",
    "    \n",
    "    return price_matrix, symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs(cointegrated_pairs):\n",
    "    return cointegrated_pairs\n",
    "\n",
    "def calculate_returns_and_spreads(price_matrix, cointegrated_pairs):\n",
    "    returns = price_matrix.pct_change().dropna()\n",
    "    \n",
    "    pairs = generate_pairs(cointegrated_pairs)\n",
    "    \n",
    "    spreads = pd.DataFrame(index=returns.index)\n",
    "    for s1, s2 in pairs:\n",
    "        spreads[f'{s1}_{s2}_spread'] = returns[s1] - returns[s2]\n",
    "        \n",
    "    return returns, spreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ml_data(returns, spreads, train_period, test_period, lookback=3):\n",
    "    ml_datasets = {}\n",
    "    \n",
    "    for spread_col in spreads.columns:\n",
    "        sym1, sym2 = spread_col.replace('_spread', '').split('_')\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            f'{sym1}_return': returns[sym1],\n",
    "            f'{sym2}_return': returns[sym2]\n",
    "        })\n",
    "        \n",
    "        for t in range(1, lookback+1):\n",
    "            df[f'{sym1}_return_t-{t}'] = df[f'{sym1}_return'].shift(t)\n",
    "            df[f'{sym2}_return_t-{t}'] = df[f'{sym2}_return'].shift(t)\n",
    "        \n",
    "        spread_next_day = (df[f'{sym1}_return'] - df[f'{sym2}_return']).shift(-1)\n",
    "        df['target'] = np.where(spread_next_day > 0, 1, 0)\n",
    "        \n",
    "        feature_cols = [col for col in df.columns if 't-' in col]\n",
    "        features = df[feature_cols].copy()\n",
    "        \n",
    "        clean_idx = features.dropna().index\n",
    "        features = features.loc[clean_idx]\n",
    "        target = df.loc[clean_idx, 'target']\n",
    "    \n",
    "        \n",
    "        train_mask = (features.index >= train_period['start']) & (features.index < train_period['end'])\n",
    "        test_mask = (features.index >= test_period['start']) & (features.index < test_period['end'])\n",
    "        \n",
    "        ml_datasets[f'{sym1}_{sym2}'] = {\n",
    "            'X_train': features[train_mask],\n",
    "            'X_test': features[test_mask],\n",
    "            'y_train': target[train_mask],\n",
    "            'y_test': target[test_mask]\n",
    "        }\n",
    "        \n",
    "    return ml_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_models(ml_datasets, coint_results):\n",
    "   results = {}\n",
    "   \n",
    "   for pair, data in tqdm(ml_datasets.items(), desc=\"Training models\"):\n",
    "       sym1, sym2 = pair.split('_')\n",
    "       \n",
    "       p_value = coint_results[\n",
    "           ((coint_results['symbol1'] == sym1) & (coint_results['symbol2'] == sym2)) |\n",
    "           ((coint_results['symbol1'] == sym2) & (coint_results['symbol2'] == sym1))\n",
    "       ]['p_value'].iloc[0]\n",
    "       \n",
    "       rf = RandomForestClassifier(\n",
    "           n_estimators=100,\n",
    "           random_state=42\n",
    "       )\n",
    "       \n",
    "       rf.fit(data['X_train'], data['y_train'])\n",
    "       predictions = rf.predict(data['X_test'])\n",
    "       \n",
    "       f1 = f1_score(data['y_test'], predictions)\n",
    "       \n",
    "       weighted_score = 1 * f1 + 0 * (1 - p_value)\n",
    "       \n",
    "       results[pair] = {\n",
    "           'model': rf,\n",
    "           'accuracy': accuracy_score(data['y_test'], predictions),\n",
    "           'precision': precision_score(data['y_test'], predictions),\n",
    "           'recall': recall_score(data['y_test'], predictions),\n",
    "           'f1': f1,\n",
    "           'p_value': p_value,\n",
    "           'weighted_score': weighted_score\n",
    "       }\n",
    "       \n",
    "       feature_importance = pd.DataFrame({\n",
    "           'feature': data['X_train'].columns,\n",
    "           'importance': rf.feature_importances_\n",
    "       }).sort_values('importance', ascending=False)\n",
    "   \n",
    "   return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from 2021-02-02 00:00:00 to 2025-01-01 00:00:00\n",
      "Total symbols: 100\n",
      "Total trading days: 1022\n"
     ]
    }
   ],
   "source": [
    "import toml\n",
    "\n",
    "with open(\"../config.toml\", \"r\") as f:\n",
    "    config = toml.load(f)\n",
    "    \n",
    "price_matrix, symbols = load_and_prepare_data(config['data']['raw_data_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing pairs: 100%|██████████| 4950/4950 [01:20<00:00, 61.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis complete!\n",
      "Found 497 cointegrated pairs\n",
      "Total pairs analyzed: 4950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models: 100%|██████████| 497/497 [01:06<00:00,  7.45it/s]\n"
     ]
    }
   ],
   "source": [
    "score_matrix, pvalue_matrix, cointegrated_pairs, coint_results = analyze_pairs(price_matrix)\n",
    "\n",
    "# plot_cointegration_heatmap(pvalue_matrix, symbols)\n",
    "\n",
    "returns, spreads = calculate_returns_and_spreads(price_matrix, cointegrated_pairs)\n",
    "\n",
    "train_period = get_training_period()\n",
    "test_period = get_test_period()\n",
    "\n",
    "ml_datasets = prepare_ml_data(returns, spreads, train_period, test_period)\n",
    "\n",
    "model_results = train_evaluate_models(ml_datasets, coint_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            pair        f1   p_value  weighted_score  accuracy  precision  \\\n",
      "45   AYWVH_QGMXV  0.601266  0.038181        0.601266  0.519084   0.510753   \n",
      "463  UJLJN_ZQLND  0.597865  0.000653        0.597865  0.568702   0.579310   \n",
      "226  GKRHI_VHRYD  0.596364  0.006685        0.596364  0.576336   0.557823   \n",
      "458  TOUNA_UECLL  0.589831  0.034507        0.589831  0.538168   0.508772   \n",
      "281  IWSHA_ZQORV  0.588235  0.031465        0.588235  0.545802   0.578231   \n",
      "476  VQWPS_YKSBR  0.587413  0.013360        0.587413  0.549618   0.552632   \n",
      "313  KHDKY_WYCMB  0.584838  0.045297        0.584838  0.561069   0.562500   \n",
      "254  GYLWO_OTBPN  0.580420  0.043421        0.580420  0.541985   0.553333   \n",
      "314  KHDKY_XPSNV  0.576779  0.001177        0.576779  0.568702   0.566176   \n",
      "157  FITJT_LURZP  0.576159  0.016441        0.576159  0.511450   0.514793   \n",
      "409  OSEHZ_ZVZYW  0.575758  0.034724        0.575758  0.572519   0.608000   \n",
      "105  EYNBG_EYWZV  0.574713  0.024178        0.574713  0.576336   0.572519   \n",
      "1    AFIWZ_FXWBG  0.574627  0.048642        0.574627  0.564885   0.578947   \n",
      "302  JAJTW_KXPSW  0.574394  0.027947        0.574394  0.530534   0.538961   \n",
      "459  TOUNA_VHRYD  0.573379  0.043063        0.573379  0.522901   0.535032   \n",
      "407  OSEHZ_XQHOA  0.572438  0.041878        0.572438  0.538168   0.558621   \n",
      "250  GULKY_XQHOA  0.568493  0.038491        0.568493  0.519084   0.532051   \n",
      "339  KXPSW_VGUCW  0.567164  0.026215        0.567164  0.557252   0.575758   \n",
      "39   AYWVH_JAWEF  0.566434  0.035561        0.566434  0.526718   0.515924   \n",
      "444  QPESE_WYCMB  0.564784  0.029240        0.564784  0.500000   0.544872   \n",
      "\n",
      "       recall  \n",
      "45   0.730769  \n",
      "463  0.617647  \n",
      "226  0.640625  \n",
      "458  0.701613  \n",
      "281  0.598592  \n",
      "476  0.626866  \n",
      "313  0.609023  \n",
      "254  0.610294  \n",
      "314  0.587786  \n",
      "157  0.654135  \n",
      "409  0.546763  \n",
      "105  0.576923  \n",
      "1    0.570370  \n",
      "302  0.614815  \n",
      "459  0.617647  \n",
      "407  0.586957  \n",
      "250  0.610294  \n",
      "339  0.558824  \n",
      "39   0.627907  \n",
      "444  0.586207  \n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame([\n",
    "   {\n",
    "       'pair': pair,\n",
    "       'accuracy': metrics['accuracy'],\n",
    "       'precision': metrics['precision'],\n",
    "       'recall': metrics['recall'],\n",
    "       'f1': metrics['f1'],\n",
    "       'p_value': metrics['p_value'],\n",
    "       'weighted_score': metrics['weighted_score']\n",
    "   }\n",
    "   for pair, metrics in model_results.items()\n",
    "])\n",
    "\n",
    "top_20 = results_df.sort_values('weighted_score', ascending=False).head(20)\n",
    "print(top_20[['pair', 'f1', 'p_value', 'weighted_score', 'accuracy', 'precision', 'recall']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(series):\n",
    "    return (series - series.mean()) / np.std(series)\n",
    "\n",
    "def calculate_spread(data, symbol1, symbol2, start_date=None, end_date=None):\n",
    "    if start_date:\n",
    "        mask = (data.index >= start_date) & (data.index <= end_date)\n",
    "        data = data[mask]\n",
    "    \n",
    "    # Calculate ratio and z-score\n",
    "    ratios = data[symbol1] / data[symbol2]\n",
    "    zscore_ratios = zscore(ratios)\n",
    "    \n",
    "    return ratios, zscore_ratios\n",
    "\n",
    "def trade(S1_train, S2_train, S1_test, S2_test, symbol1, symbol2, window1=5, window2=60):\n",
    "    ratios_train = S1_train / S2_train\n",
    "    ma2_train = ratios_train.rolling(window=window2, center=False).mean()\n",
    "    std_train = ratios_train.rolling(window=window2, center=False).std()\n",
    "    \n",
    "    ratios_test = S1_test / S2_test\n",
    "    trades = []\n",
    "    trade_id = 0\n",
    "    position = 0\n",
    "    entry_prices = None\n",
    "    entry_date = None\n",
    "    \n",
    "    for i in range(len(ratios_test)):\n",
    "        current_ratio = ratios_test.iloc[i]\n",
    "        current_date = ratios_test.index[i]\n",
    "        \n",
    "        ma2_test = ratios_test.iloc[:i+1].rolling(window=window2, center=False).mean().iloc[-1]\n",
    "        std_test = ratios_test.iloc[:i+1].rolling(window=window2, center=False).std().iloc[-1]\n",
    "        zscore = (current_ratio - ma2_test) / std_test\n",
    "        \n",
    "        if position == 0:\n",
    "            if zscore > 1.0:\n",
    "                entry_date = current_date\n",
    "                entry_prices = {\n",
    "                    symbol1: {\"price\": S1_test.iloc[i], \"type\": \"short\"},\n",
    "                    symbol2: {\"price\": S2_test.iloc[i], \"type\": \"long\"}\n",
    "                }\n",
    "                position = -1\n",
    "                \n",
    "            elif zscore < -1.0:\n",
    "                entry_date = current_date\n",
    "                entry_prices = {\n",
    "                    symbol1: {\"price\": S1_test.iloc[i], \"type\": \"long\"},\n",
    "                    symbol2: {\"price\": S2_test.iloc[i], \"type\": \"short\"}\n",
    "                }\n",
    "                position = 1\n",
    "                \n",
    "        elif abs(zscore) < 0.5 and position != 0:\n",
    "            for symbol in [symbol1, symbol2]:\n",
    "                trades.append({\n",
    "                    'trade_id': trade_id,\n",
    "                    'symbol': symbol,\n",
    "                    'entry_date': entry_date,\n",
    "                    'entry_price': entry_prices[symbol][\"price\"],\n",
    "                    'exit_date': current_date,\n",
    "                    'exit_price': S1_test.iloc[i] if symbol == symbol1 else S2_test.iloc[i],\n",
    "                    'position_type': entry_prices[symbol][\"type\"],\n",
    "                    'paired_symbol': symbol2 if symbol == symbol1 else symbol1,\n",
    "                    'exit_type': 'target'\n",
    "                })\n",
    "            position = 0\n",
    "            trade_id += 1\n",
    "            \n",
    "    return trades\n",
    "\n",
    "def backtest_pairs(price_matrix, pairs, train_end_date):\n",
    "    all_trades = []\n",
    "    \n",
    "    for symbol1, symbol2 in pairs:\n",
    "        training_mask = price_matrix.index < train_end_date\n",
    "        \n",
    "        S1_train = price_matrix[symbol1][training_mask]\n",
    "        S2_train = price_matrix[symbol2][training_mask]\n",
    "        S1_test = price_matrix[symbol1][~training_mask]\n",
    "        S2_test = price_matrix[symbol2][~training_mask]\n",
    "        \n",
    "        pair_trades = trade(S1_train, S2_train, S1_test, S2_test, symbol1, symbol2)\n",
    "        all_trades.extend(pair_trades)\n",
    "    \n",
    "    trades_df = pd.DataFrame(all_trades)\n",
    "    trades_df.to_parquet('../../data/results/Random-Forest_Z-Score.parquet')\n",
    "    \n",
    "    return trades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Backtest Results:\n",
      "Total number of trades: 342\n"
     ]
    }
   ],
   "source": [
    "top_pairs = [tuple(pair.split('_')) for pair in top_20['pair']]\n",
    "\n",
    "trades_df = backtest_pairs(price_matrix, top_pairs, train_period['end'])\n",
    "\n",
    "print(\"\\nBacktest Results:\")\n",
    "print(f\"Total number of trades: {len(trades_df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

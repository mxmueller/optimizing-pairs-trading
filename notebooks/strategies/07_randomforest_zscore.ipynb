{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from src.analysis.cointegration import find_cointegrated_pairs, analyze_pairs, plot_cointegration_heatmap\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import coint\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATE_CONFIG = {\n",
    "    'TRAIN_START': pd.Timestamp('2021-02-02'),\n",
    "    'TRAIN_END': pd.Timestamp('2024-01-01'),\n",
    "    'TEST_END': pd.Timestamp('2025-01-01'),\n",
    "    'TRADING_DAYS_PER_YEAR': 252  \n",
    "}\n",
    "\n",
    "def get_training_period():\n",
    "    return {\n",
    "        'start': DATE_CONFIG['TRAIN_START'],\n",
    "        'end': DATE_CONFIG['TRAIN_END']\n",
    "    }\n",
    "\n",
    "def get_test_period():\n",
    "    return {\n",
    "        'start': DATE_CONFIG['TRAIN_END'],\n",
    "        'end': DATE_CONFIG['TEST_END']\n",
    "    }\n",
    "\n",
    "def get_training_days():\n",
    "    years = (DATE_CONFIG['TRAIN_END'] - DATE_CONFIG['TRAIN_START']).days / 365\n",
    "    return int(years * DATE_CONFIG['TRADING_DAYS_PER_YEAR'])\n",
    "\n",
    "plt.style.use('classic')\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path):\n",
    "\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    mask = (df['date'] >= DATE_CONFIG['TRAIN_START']) & \\\n",
    "           (df['date'] <= DATE_CONFIG['TEST_END'])\n",
    "    df = df[mask]\n",
    "    \n",
    "    price_matrix = df.pivot(index='date', columns='symbol', values='close')\n",
    "    \n",
    "    symbols = price_matrix.columns.tolist()\n",
    "    \n",
    "    print(f\"Loaded data from {DATE_CONFIG['TRAIN_START']} to {DATE_CONFIG['TEST_END']}\")\n",
    "    print(f\"Total symbols: {len(symbols)}\")\n",
    "    print(f\"Total trading days: {len(price_matrix)}\")\n",
    "    \n",
    "    return price_matrix, symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs(cointegrated_pairs):\n",
    "    return cointegrated_pairs\n",
    "\n",
    "def calculate_returns_and_spreads(price_matrix, cointegrated_pairs):\n",
    "    returns = price_matrix.pct_change().dropna()\n",
    "    \n",
    "    pairs = generate_pairs(cointegrated_pairs)\n",
    "    \n",
    "    spreads = pd.DataFrame(index=returns.index)\n",
    "    for s1, s2 in pairs:\n",
    "        spreads[f'{s1}_{s2}_spread'] = returns[s1] - returns[s2]\n",
    "        \n",
    "    return returns, spreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ml_data(returns, spreads, train_period, test_period, lookback=3):\n",
    "    ml_datasets = {}\n",
    "    \n",
    "    for spread_col in spreads.columns:\n",
    "        sym1, sym2 = spread_col.replace('_spread', '').split('_')\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            f'{sym1}_return': returns[sym1],\n",
    "            f'{sym2}_return': returns[sym2]\n",
    "        })\n",
    "        \n",
    "        for t in range(1, lookback+1):\n",
    "            df[f'{sym1}_return_t-{t}'] = df[f'{sym1}_return'].shift(t)\n",
    "            df[f'{sym2}_return_t-{t}'] = df[f'{sym2}_return'].shift(t)\n",
    "        \n",
    "        spread_next_day = (df[f'{sym1}_return'] - df[f'{sym2}_return']).shift(-1)\n",
    "        df['target'] = np.where(spread_next_day > 0, 1, 0)\n",
    "        \n",
    "        feature_cols = [col for col in df.columns if 't-' in col]\n",
    "        features = df[feature_cols].copy()\n",
    "        \n",
    "        clean_idx = features.dropna().index\n",
    "        features = features.loc[clean_idx]\n",
    "        target = df.loc[clean_idx, 'target']\n",
    "    \n",
    "        \n",
    "        train_mask = (features.index >= train_period['start']) & (features.index < train_period['end'])\n",
    "        test_mask = (features.index >= test_period['start']) & (features.index < test_period['end'])\n",
    "        \n",
    "        ml_datasets[f'{sym1}_{sym2}'] = {\n",
    "            'X_train': features[train_mask],\n",
    "            'X_test': features[test_mask],\n",
    "            'y_train': target[train_mask],\n",
    "            'y_test': target[test_mask]\n",
    "        }\n",
    "        \n",
    "    return ml_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_models(ml_datasets, coint_results):\n",
    "   results = {}\n",
    "   \n",
    "   for pair, data in tqdm(ml_datasets.items(), desc=\"Training models\"):\n",
    "       sym1, sym2 = pair.split('_')\n",
    "       \n",
    "       p_value = coint_results[\n",
    "           ((coint_results['symbol1'] == sym1) & (coint_results['symbol2'] == sym2)) |\n",
    "           ((coint_results['symbol1'] == sym2) & (coint_results['symbol2'] == sym1))\n",
    "       ]['p_value'].iloc[0]\n",
    "       \n",
    "       rf = RandomForestClassifier(\n",
    "           n_estimators=100,\n",
    "           random_state=42\n",
    "       )\n",
    "       \n",
    "       rf.fit(data['X_train'], data['y_train'])\n",
    "       predictions = rf.predict(data['X_test'])\n",
    "       \n",
    "       f1 = f1_score(data['y_test'], predictions)\n",
    "       \n",
    "       weighted_score = 0.6 * f1 + 0.4 * (1 - p_value)\n",
    "       \n",
    "       results[pair] = {\n",
    "           'model': rf,\n",
    "           'accuracy': accuracy_score(data['y_test'], predictions),\n",
    "           'precision': precision_score(data['y_test'], predictions),\n",
    "           'recall': recall_score(data['y_test'], predictions),\n",
    "           'f1': f1,\n",
    "           'p_value': p_value,\n",
    "           'weighted_score': weighted_score\n",
    "       }\n",
    "       \n",
    "       feature_importance = pd.DataFrame({\n",
    "           'feature': data['X_train'].columns,\n",
    "           'importance': rf.feature_importances_\n",
    "       }).sort_values('importance', ascending=False)\n",
    "   \n",
    "   return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from 2021-02-02 00:00:00 to 2025-01-01 00:00:00\n",
      "Total symbols: 94\n",
      "Total trading days: 985\n"
     ]
    }
   ],
   "source": [
    "import toml\n",
    "\n",
    "with open(\"../config.toml\", \"r\") as f:\n",
    "    config = toml.load(f)\n",
    "    \n",
    "price_matrix, symbols = load_and_prepare_data(config['data']['raw_data_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing pairs: 100%|██████████| 4371/4371 [00:53<00:00, 81.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis complete!\n",
      "Found 244 cointegrated pairs\n",
      "Total pairs analyzed: 4371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  80%|███████▉  | 194/244 [00:23<00:06,  8.24it/s]"
     ]
    }
   ],
   "source": [
    "score_matrix, pvalue_matrix, cointegrated_pairs, coint_results = analyze_pairs(price_matrix)\n",
    "\n",
    "# plot_cointegration_heatmap(pvalue_matrix, symbols)\n",
    "\n",
    "returns, spreads = calculate_returns_and_spreads(price_matrix, cointegrated_pairs)\n",
    "\n",
    "train_period = get_training_period()\n",
    "test_period = get_test_period()\n",
    "\n",
    "ml_datasets = prepare_ml_data(returns, spreads, train_period, test_period)\n",
    "\n",
    "model_results = train_evaluate_models(ml_datasets, coint_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame([\n",
    "   {\n",
    "       'pair': pair,\n",
    "       'accuracy': metrics['accuracy'],\n",
    "       'precision': metrics['precision'],\n",
    "       'recall': metrics['recall'],\n",
    "       'f1': metrics['f1'],\n",
    "       'p_value': metrics['p_value'],\n",
    "       'weighted_score': metrics['weighted_score']\n",
    "   }\n",
    "   for pair, metrics in model_results.items()\n",
    "])\n",
    "\n",
    "top_20 = results_df.sort_values('weighted_score', ascending=False).head(20)\n",
    "print(top_20[['pair', 'f1', 'p_value', 'weighted_score', 'accuracy', 'precision', 'recall']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(series):\n",
    "    return (series - series.mean()) / np.std(series)\n",
    "\n",
    "def calculate_spread(data, symbol1, symbol2, start_date=None, end_date=None):\n",
    "    if start_date:\n",
    "        mask = (data.index >= start_date) & (data.index <= end_date)\n",
    "        data = data[mask]\n",
    "    \n",
    "    # Calculate ratio and z-score\n",
    "    ratios = data[symbol1] / data[symbol2]\n",
    "    zscore_ratios = zscore(ratios)\n",
    "    \n",
    "    return ratios, zscore_ratios\n",
    "\n",
    "def trade(S1_train, S2_train, S1_test, S2_test, symbol1, symbol2, window1=5, window2=60):\n",
    "    ratios_train = S1_train / S2_train\n",
    "    ma2_train = ratios_train.rolling(window=window2, center=False).mean()\n",
    "    std_train = ratios_train.rolling(window=window2, center=False).std()\n",
    "    \n",
    "    ratios_test = S1_test / S2_test\n",
    "    trades = []\n",
    "    trade_id = 0\n",
    "    position = 0\n",
    "    entry_prices = None\n",
    "    entry_date = None\n",
    "    \n",
    "    for i in range(len(ratios_test)):\n",
    "        current_ratio = ratios_test.iloc[i]\n",
    "        current_date = ratios_test.index[i]\n",
    "        \n",
    "        ma2_test = ratios_test.iloc[:i+1].rolling(window=window2, center=False).mean().iloc[-1]\n",
    "        std_test = ratios_test.iloc[:i+1].rolling(window=window2, center=False).std().iloc[-1]\n",
    "        zscore = (current_ratio - ma2_test) / std_test\n",
    "        \n",
    "        if position == 0:\n",
    "            if zscore > 1.0:\n",
    "                entry_date = current_date\n",
    "                entry_prices = {\n",
    "                    symbol1: {\"price\": S1_test.iloc[i], \"type\": \"short\"},\n",
    "                    symbol2: {\"price\": S2_test.iloc[i], \"type\": \"long\"}\n",
    "                }\n",
    "                position = -1\n",
    "                \n",
    "            elif zscore < -1.0:\n",
    "                entry_date = current_date\n",
    "                entry_prices = {\n",
    "                    symbol1: {\"price\": S1_test.iloc[i], \"type\": \"long\"},\n",
    "                    symbol2: {\"price\": S2_test.iloc[i], \"type\": \"short\"}\n",
    "                }\n",
    "                position = 1\n",
    "                \n",
    "        elif abs(zscore) < 0.5 and position != 0:\n",
    "            for symbol in [symbol1, symbol2]:\n",
    "                trades.append({\n",
    "                    'trade_id': trade_id,\n",
    "                    'symbol': symbol,\n",
    "                    'entry_date': entry_date,\n",
    "                    'entry_price': entry_prices[symbol][\"price\"],\n",
    "                    'exit_date': current_date,\n",
    "                    'exit_price': S1_test.iloc[i] if symbol == symbol1 else S2_test.iloc[i],\n",
    "                    'position_type': entry_prices[symbol][\"type\"],\n",
    "                    'paired_symbol': symbol2 if symbol == symbol1 else symbol1,\n",
    "                    'exit_type': 'target'\n",
    "                })\n",
    "            position = 0\n",
    "            trade_id += 1\n",
    "            \n",
    "    return trades\n",
    "\n",
    "def backtest_pairs(price_matrix, pairs, train_end_date):\n",
    "    all_trades = []\n",
    "    \n",
    "    for symbol1, symbol2 in pairs:\n",
    "        training_mask = price_matrix.index < train_end_date\n",
    "        \n",
    "        S1_train = price_matrix[symbol1][training_mask]\n",
    "        S2_train = price_matrix[symbol2][training_mask]\n",
    "        S1_test = price_matrix[symbol1][~training_mask]\n",
    "        S2_test = price_matrix[symbol2][~training_mask]\n",
    "        \n",
    "        pair_trades = trade(S1_train, S2_train, S1_test, S2_test, symbol1, symbol2)\n",
    "        all_trades.extend(pair_trades)\n",
    "    \n",
    "    trades_df = pd.DataFrame(all_trades)\n",
    "    trades_df.to_parquet('../../data/results/Random-Forest_Z-Score.parquet')\n",
    "    \n",
    "    return trades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pairs = [tuple(pair.split('_')) for pair in top_20['pair']]\n",
    "\n",
    "trades_df = backtest_pairs(price_matrix, top_pairs, train_period['end'])\n",
    "\n",
    "print(\"\\nBacktest Results:\")\n",
    "print(f\"Total number of trades: {len(trades_df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
